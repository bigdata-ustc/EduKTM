{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the Cognitive Diagnosis Benchmark Datasets (CDBD)\n",
    "from EduData import get_data\n",
    "\n",
    "get_data(\"assistment-2009-2010-skill\", \"../../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7577, 20) 167068\n",
      "number of students is 3559, number of problems is 7577\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the original data, take students' first-attempt responses, selecte the 20 most frequent knowledge concepts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "origin_data = []\n",
    "non_repeat_data = defaultdict(dict) \n",
    "skill_count = defaultdict(int)\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/skill_builder_data_corrected.csv\", encoding='utf-8',  errors='ignore') as file:\n",
    "    next(file)\n",
    "    for fileline in file:\n",
    "        row = fileline.split(',')\n",
    "        order = int(row[0])\n",
    "        stu_id = int(row[2])\n",
    "        prob_id = int(row[4])\n",
    "        correct = int(row[6])\n",
    "        answer_type = row[10]\n",
    "        try:\n",
    "            skill_id = int(row[16])\n",
    "            if answer_type != 'open_response': \n",
    "                if prob_id not in non_repeat_data[stu_id]:\n",
    "                    origin_data.append([order, stu_id, prob_id, correct, skill_id])\n",
    "                    skill_count[skill_id] += 1\n",
    "                    non_repeat_data[stu_id][prob_id] = [order, stu_id, prob_id, correct, skill_id]\n",
    "                else:  # not the first attempt\n",
    "                    his_att = non_repeat_data[stu_id][prob_id]\n",
    "                    idx = origin_data.index(his_att)\n",
    "                    if his_att[0] > order:\n",
    "                        origin_data[idx] = [order, stu_id, prob_id, correct, skill_id]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "know_num = 20  # 20 most frequent knowledge\n",
    "skill_20 = sorted(skill_count, key=lambda x:skill_count[x], reverse=True)[:know_num]  \n",
    "q_m = []  # Q-matrix\n",
    "stu_dict, prob_dict = {},{}\n",
    "data = []\n",
    "stu_idx, prob_idx = 0, 0\n",
    "for record in origin_data:\n",
    "    order, stu, prob, answer, skill = record\n",
    "    if skill in skill_20:\n",
    "        skill_new_idx = skill_20.index(skill)\n",
    "        if stu not in stu_dict:\n",
    "            stu_dict[stu] = stu_idx\n",
    "            stu_idx += 1\n",
    "        if prob not in prob_dict:\n",
    "            prob_dict[prob] = prob_idx\n",
    "            prob_idx += 1\n",
    "            q_m_row = np.zeros(shape=know_num)\n",
    "            q_m_row[skill_new_idx] = 1\n",
    "            q_m.append(q_m_row)\n",
    "        data.append([stu_dict[stu], prob_dict[prob], answer, order])\n",
    "q_m = np.array(q_m)\n",
    "data = sorted(data, key=lambda x:x[3])\n",
    "print(q_m.shape, len(data))\n",
    "print(\"number of students is %d, number of problems is %d\" % (stu_idx, prob_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data into multiple time windows, split train/test data\n",
    "time_window_num = 7\n",
    "\n",
    "stu_data = defaultdict(list)\n",
    "for record in data:\n",
    "    stu, prob, rating, time = record\n",
    "    stu_data[int(stu)].append({'user_id': int(stu), 'item_id': int(prob), 'score': rating})\n",
    "\n",
    "# split dataset\n",
    "train_logs, test_logs = [], []\n",
    "for t in range(time_window_num):\n",
    "    t_train = []\n",
    "    for stu in stu_data:\n",
    "        split_len = int(len(stu_data[stu])/time_window_num)\n",
    "        if t != time_window_num-1:\n",
    "            t_train += stu_data[stu][t*split_len:(t+1)*split_len]\n",
    "        else:\n",
    "            for j in range(t*split_len, len(stu_data[stu])):\n",
    "                if np.random.random() < 0.5:\n",
    "                    t_train.append(stu_data[stu][j])\n",
    "                else:\n",
    "                    test_logs.append(stu_data[stu][j])\n",
    "    random.shuffle(t_train)\n",
    "    train_logs.append(t_train)\n",
    "\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/train_data.json\", 'w', encoding='utf8') as file:\n",
    "    json.dump(train_logs, file, indent=4, ensure_ascii=False)\n",
    "with open(\"../../data/2009_skill_builder_data_corrected/test_data.json\", 'w', encoding='utf8') as file:\n",
    "    json.dump(test_logs, file, indent=4, ensure_ascii=False)\n",
    "np.savetxt(\"../../data/2009_skill_builder_data_corrected/q_m.csv\", q_m, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
