{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Learning Behavior-oriented Knowledge Tracing(LBKT)\n",
    "\n",
    "This notebook will show you how to train and use the LBKT. First, we will show how to get the data (here we use assistment-2009 as the dataset). Then we will show how to train a LBKT and perform the parameters persistence. At last, we will show how to load the parameters from the file and evaluate on the test dataset.\n",
    "\n",
    "The script version could be found in [LBKT.py](LBKT.py)\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Before we process the data, we need to first acquire the dataset which is shown in [data_preprocess.ipynb](data_preprocess.ipynb)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load_data import DATA\n",
    "\n",
    "def generate_q_matrix(path, n_skill, n_problem, gamma=0):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            problem2skill = eval(line)\n",
    "    q_matrix = np.zeros((n_problem + 1, n_skill + 1)) + gamma\n",
    "    for p in problem2skill.keys():\n",
    "        q_matrix[p][problem2skill[p]] = 1\n",
    "    return q_matrix\n",
    "\n",
    "\n",
    "n_question = 123\n",
    "memory_size = n_question + 1\n",
    "n_exercises = 17751\n",
    "\n",
    "\n",
    "seqlen = 100\n",
    "dim_tp = 128\n",
    "num_resps = 2\n",
    "num_units = 128\n",
    "dropout  = 0.2 \n",
    "dim_hidden = 50\n",
    "batch_size = 32\n",
    "q_gamma = 0.01\n",
    "\n",
    "dat = DATA(seqlen=seqlen, separate_char=',')\n",
    "data_path = '../../data/2009_skill_builder_data_corrected/'\n",
    "train_data = dat.load_data(data_path + 'train.txt')\n",
    "test_data = dat.load_data(data_path + 'test.txt')\n",
    "q_matrix = generate_q_matrix(\n",
    "    data_path + 'problem2skill',\n",
    "    n_question, n_exercises,\n",
    "    q_gamma\n",
    ")"
   ]
  },
  {
   "source": [
    "## Training and Persistence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from EduKTM import LBKT\n",
    "\n",
    "lbkt = LBKT(n_exercises,dim_tp, num_resps,num_units, dropout,dim_hidden,memory_size,batch_size,q_matrix)\n",
    "lbkt.train(train_data, test_data, epoch=2, lr=0.001)\n",
    "lbkt.save(\"lbkt.params\")\n"
   ]
  },
  {
   "source": [
    "## Loading and Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbkt.load(\"lbkt.params\")\n",
    "_, auc, accuracy, rmse = lbkt.eval(test_data)\n",
    "print(\"auc: %.6f, accuracy: %.6f, rmse: %.6f\" % (auc, accuracy, rmse))"
   ]
  }
 ]
}
