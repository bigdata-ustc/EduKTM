{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from EduData import get_data\n",
    "import os\n",
    "\n",
    "if not os.path.exists('../../data/anonymized_full_release_competition_dataset/anonymized_full_release_competition_dataset.csv'):\n",
    "    get_data(\"assistment-2017\", \"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "data = pd.read_csv(\n",
    "    '../../data/anonymized_full_release_competition_dataset/anonymized_full_release_competition_dataset.csv',\n",
    "    usecols=['startTime', 'timeTaken', 'studentId', 'skill', 'problemId', 'correct']\n",
    ").dropna(subset=['skill', 'problemId']).sort_values('startTime')\n",
    "\n",
    "data.timeTaken = data.timeTaken.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of skills: 102\n",
      "number of problems: 3162\n",
      "number of answer time: 1326\n"
     ]
    }
   ],
   "source": [
    "skills = data.skill.unique().tolist()\n",
    "problems = data.problemId.unique().tolist()\n",
    "at = data.timeTaken.unique()\n",
    "\n",
    "# question id from 1 to #num_skill\n",
    "skill2id = { p: i+1 for i, p in enumerate(skills) }\n",
    "problem2id = { p: i+1 for i, p in enumerate(problems) }\n",
    "at2id = { a: i for i, a in enumerate(at) }\n",
    "\n",
    "print(\"number of skills: %d\" % len(skills))\n",
    "print(\"number of problems: %d\" % len(problems))\n",
    "print(\"number of answer time: %d\" % len(at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of interval time: 2839\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "it = set()\n",
    "# calculate interval time\n",
    "for u in data.studentId.unique():\n",
    "    startTime = np.array(data[data.studentId == u].startTime)\n",
    "    for i in range(1, len(startTime)):\n",
    "        item = (startTime[i] - startTime[i - 1]) // 60\n",
    "        if item > 43200:\n",
    "            item = 43200\n",
    "        it.add(item)\n",
    "\n",
    "it2id = { a: i for i, a in enumerate(it) }\n",
    "print(\"number of interval time: %d\" % len(it))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# problems to skills\n",
    "problem2skill = {}\n",
    "for s, p in zip(np.array(data.skill), np.array(data.problemId)):\n",
    "    problem2skill[problem2id[p]] = skill2id[s]\n",
    "with open('../../data/anonymized_full_release_competition_dataset/problem2skill', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(problem2skill))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parse student sequence:\t: 100%|██████████| 1709/1709 [00:03<00:00, 494.89it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_all_seq(students):\n",
    "    all_sequences = []\n",
    "    for student_id in tqdm.tqdm(students, 'parse student sequence:\\t'):\n",
    "        student_sequence = parse_student_seq(data[data.studentId == student_id])\n",
    "        all_sequences.extend([student_sequence])\n",
    "    return all_sequences\n",
    "\n",
    "\n",
    "def parse_student_seq(student):\n",
    "    seq = student\n",
    "    s = [skill2id[q] for q in seq.skill.tolist()]\n",
    "    a = seq.correct.tolist()\n",
    "    p = [problem2id[p] for p in seq.problemId.tolist()]\n",
    "    it = [0]\n",
    "    startTime = np.array(seq.startTime)\n",
    "    for i in range(1, len(startTime)):\n",
    "        item = (startTime[i] - startTime[i - 1]) // 60\n",
    "        if item > 43200:\n",
    "            item = 43200\n",
    "        it.append(it2id[item])\n",
    "    at = [at2id[int(x)] for x in seq.timeTaken.tolist()]\n",
    "    return s, a, p, it, at\n",
    "\n",
    "\n",
    "sequences = parse_all_seq(data.studentId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-1c28f935530e>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_data = np.array(train_data)\n",
      "<ipython-input-7-1c28f935530e>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_data = np.array(test_data)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# split train data and test data\n",
    "train_data, test_data = train_test_split(sequences, test_size=.2, random_state=10)\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write data into file: ../../data/anonymized_full_release_competition_dataset/train0.txt: 100%|██████████| 1093/1093 [00:00<00:00, 1685.70it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/valid0.txt: 100%|██████████| 274/274 [00:00<00:00, 1639.16it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/train1.txt: 100%|██████████| 1093/1093 [00:00<00:00, 1676.09it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/valid1.txt: 100%|██████████| 274/274 [00:00<00:00, 1914.76it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/train2.txt: 100%|██████████| 1094/1094 [00:00<00:00, 1649.17it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/valid2.txt: 100%|██████████| 273/273 [00:00<00:00, 1745.17it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/train3.txt: 100%|██████████| 1094/1094 [00:00<00:00, 1725.93it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/valid3.txt: 100%|██████████| 273/273 [00:00<00:00, 1729.58it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/train4.txt: 100%|██████████| 1094/1094 [00:00<00:00, 1707.89it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/valid4.txt: 100%|██████████| 273/273 [00:00<00:00, 1404.57it/s]\n",
      "write data into file: ../../data/anonymized_full_release_competition_dataset/test.txt: 100%|██████████| 342/342 [00:00<00:00, 1470.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def sequences2l(sequences, trg_path):\n",
    "    with open(trg_path, 'a', encoding='utf8') as f:\n",
    "        for seq in tqdm.tqdm(sequences, 'write data into file: %s' % trg_path):\n",
    "            s_seq, a_seq, p_seq, it_seq, at_seq = seq\n",
    "            seq_len = len(s_seq)\n",
    "            f.write(str(seq_len) + '\\n')\n",
    "            f.write(','.join([str(s) for s in s_seq]) + '\\n')\n",
    "            f.write(','.join([str(a) for a in a_seq]) + '\\n')\n",
    "            f.write(','.join([str(p) for p in p_seq]) + '\\n')\n",
    "            f.write(','.join([str(i) for i in it_seq]) + '\\n')\n",
    "            f.write(','.join([str(a) for a in at_seq]) + '\\n')\n",
    "\n",
    "# split into 5 folds\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "idx = 0\n",
    "for train_data_1, valid_data in kfold.split(train_data):\n",
    "    sequences2l(train_data[train_data_1], '../../data/anonymized_full_release_competition_dataset/train' + str(idx) + '.txt')\n",
    "    sequences2l(train_data[valid_data], '../../data/anonymized_full_release_competition_dataset/valid' + str(idx) + '.txt')\n",
    "    idx += 1\n",
    "\n",
    "sequences2l(test_data, '../../data/anonymized_full_release_competition_dataset/test.txt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}