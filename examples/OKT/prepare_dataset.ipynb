{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from EduData import get_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/anonymized_full_release_competition_dataset'\n",
    "\n",
    "if not os.path.exists(path + '/anonymized_full_release_competition_dataset.csv'):\n",
    "  get_data(\"assistment-2017\", \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "  path + '/anonymized_full_release_competition_dataset.csv',\n",
    "  usecols=['startTime', 'endTime', 'timeTaken', 'studentId', 'skill', 'problemId', 'correct']\n",
    ").dropna(subset=['skill', 'problemId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.timeTaken = data.timeTaken.astype(int)\n",
    "\n",
    "skills = data.skill.unique().tolist()\n",
    "problems = data.problemId.unique().tolist()\n",
    "at = data.timeTaken.unique()\n",
    "user_seqs = [u.sort_values('endTime') for _, u in list(data.groupby('studentId'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question id from 1 to #num_skill\n",
    "skill2id = {p: i + 1 for i, p in enumerate(skills)}\n",
    "problem2id = {p: i + 1 for i, p in enumerate(problems)}\n",
    "at2id = {a: i for i, a in enumerate(at)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = set()\n",
    "avg_it = np.array([])\n",
    "# calculate interval time\n",
    "for i, seq in enumerate(user_seqs):\n",
    "  seq = seq.copy()\n",
    "  items = seq.endTime.diff(1) // 60\n",
    "  items.iloc[0] = 0\n",
    "  items = items.astype(int)\n",
    "  items[items > 43200] = 43200\n",
    "  seq['it'] = items\n",
    "  user_seqs[i] = seq\n",
    "  for item in items.unique():\n",
    "    it.add(item)\n",
    "\n",
    "it2id = {a: i for i, a in enumerate(it)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parse student sequence:\t: 100%|██████████| 1709/1709 [00:01<00:00, 1439.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_all_seq(students):\n",
    "  all_sequences = []\n",
    "  for seq in tqdm.tqdm(students, 'parse student sequence:\\t'):\n",
    "    student_sequence = parse_student_seq(seq)\n",
    "    all_sequences.extend([student_sequence])\n",
    "  return all_sequences\n",
    "\n",
    "\n",
    "def parse_student_seq(student):\n",
    "  seq = student\n",
    "  s = [skill2id[q] for q in seq.skill.tolist()]\n",
    "  a = seq.correct.tolist()\n",
    "  p = [problem2id[p] for p in seq.problemId.tolist()]\n",
    "  it = [it2id[int(x)] for x in seq.it.tolist()]\n",
    "  at = [at2id[int(x)] for x in seq.timeTaken.tolist()]\n",
    "  return s, a, p, it, at\n",
    "\n",
    "sequences = parse_all_seq(user_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parse student sequence:\t: 100%|██████████| 1709/1709 [00:00<00:00, 2218.42it/s]\n"
     ]
    }
   ],
   "source": [
    "sequences = parse_all_seq(user_seqs)\n",
    "\n",
    "# split train data and test data\n",
    "train_data, test_data = train_test_split(sequences, test_size=.2, random_state=5)\n",
    "train_data = np.array(train_data, dtype=object)\n",
    "test_data = np.array(test_data, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write data into file ./data/anonymized_full_release_competition_dataset/train0.txt: 100%|██████████| 1093/1093 [00:00<00:00, 1824.67it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/valid0.txt: 100%|██████████| 274/274 [00:00<00:00, 2092.50it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/train1.txt: 100%|██████████| 1093/1093 [00:00<00:00, 2009.51it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/valid1.txt: 100%|██████████| 274/274 [00:00<00:00, 2070.91it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/train2.txt: 100%|██████████| 1094/1094 [00:00<00:00, 2044.91it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/valid2.txt: 100%|██████████| 273/273 [00:00<00:00, 1515.39it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/train3.txt: 100%|██████████| 1094/1094 [00:00<00:00, 1903.32it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/valid3.txt: 100%|██████████| 273/273 [00:00<00:00, 1799.80it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/train4.txt: 100%|██████████| 1094/1094 [00:00<00:00, 1738.26it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/valid4.txt: 100%|██████████| 273/273 [00:00<00:00, 1942.51it/s]\n",
      "write data into file ./data/anonymized_full_release_competition_dataset/test.txt: 100%|██████████| 342/342 [00:00<00:00, 1950.58it/s]\n"
     ]
    }
   ],
   "source": [
    "def sequences2l(sequences, trg_path):\n",
    "  with open(trg_path, 'a', encoding='utf8') as f:\n",
    "    for seq in tqdm.tqdm(sequences, 'write data into file %s' % trg_path):\n",
    "      s_seq, a_seq, p_seq, it_seq, at_seq = seq\n",
    "      seq_len = len(s_seq)\n",
    "      f.write(str(seq_len) + '\\n')\n",
    "      f.write(','.join([str(s) for s in s_seq]) + '\\n')\n",
    "      f.write(','.join([str(a) for a in a_seq]) + '\\n')\n",
    "      f.write(','.join([str(p) for p in p_seq]) + '\\n')\n",
    "      f.write(','.join([str(i) for i in it_seq]) + '\\n')\n",
    "      f.write(','.join([str(a) for a in at_seq]) + '\\n')\n",
    "\n",
    "\n",
    "# split into 5 folds\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "idx = 0\n",
    "for train_data_1, valid_data in kfold.split(train_data):\n",
    "  sequences2l(train_data[train_data_1], path + '/train' + str(idx) + '.txt')\n",
    "  sequences2l(train_data[valid_data], path + '/valid' + str(idx) + '.txt')\n",
    "  idx += 1\n",
    "\n",
    "sequences2l(test_data, path + '/test.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
